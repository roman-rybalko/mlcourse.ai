{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "OzpKEZNL_4Rv",
    "outputId": "2206506f-c3ed-4d42-9a63-7f23d35ae730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-22 20:27:49--  https://github.com/roman-rybalko/telegram-data-clustering-contest/archive/8da391a6b6d952bbf0555e8a80ff864cf9c79bda.zip\r\n",
      "Resolving github.com (github.com)... 140.82.118.4\r\n",
      "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://codeload.github.com/roman-rybalko/telegram-data-clustering-contest/zip/8da391a6b6d952bbf0555e8a80ff864cf9c79bda [following]\r\n",
      "--2019-11-22 20:27:49--  https://codeload.github.com/roman-rybalko/telegram-data-clustering-contest/zip/8da391a6b6d952bbf0555e8a80ff864cf9c79bda\r\n",
      "Resolving codeload.github.com (codeload.github.com)... 192.30.253.121\r\n",
      "Connecting to codeload.github.com (codeload.github.com)|192.30.253.121|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/zip]\r\n",
      "Saving to: ‘d2.zip’\r\n",
      "\r\n",
      "d2.zip                  [   <=>              ] 982.42M  24.1MB/s    in 97s     \r\n",
      "\r\n",
      "2019-11-22 20:29:27 (10.1 MB/s) - ‘d2.zip’ saved [1030146926]\r\n",
      "\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191101' -> './dataset/20191101'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191102' -> './dataset/20191102'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191103' -> './dataset/20191103'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191104' -> './dataset/20191104'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191105' -> './dataset/20191105'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191106' -> './dataset/20191106'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset1/20191107' -> './dataset/20191107'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191108' -> './dataset/20191108'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191109' -> './dataset/20191109'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191110' -> './dataset/20191110'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191111' -> './dataset/20191111'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191112' -> './dataset/20191112'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191113' -> './dataset/20191113'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191114' -> './dataset/20191114'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191115' -> './dataset/20191115'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191116' -> './dataset/20191116'\r\n",
      "renamed 'telegram-data-clustering-contest-8da391a6b6d952bbf0555e8a80ff864cf9c79bda/dataset2/20191117' -> './dataset/20191117'\r\n"
     ]
    }
   ],
   "source": [
    "#!wget -c https://github.com/roman-rybalko/telegram-data-clustering-contest/archive/8da391a6b6d952bbf0555e8a80ff864cf9c79bda.zip -O d2.zip\n",
    "#!unzip -uq d2.zip\n",
    "#!mkdir dataset\n",
    "#!mv -v */dataset1/* */dataset2/* ./dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IueDsHdCW4xz",
    "outputId": "985de406-db6e-4169-ed87-ee400633e1b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467483"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def get_files(d):\n",
    "  return [os.path.join(dp, f) for dp, dn, fn in os.walk(d) for f in fn]\n",
    "files = [f for f in get_files('dataset') if os.path.splitext(f)[1] == '.html']\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2z6aa1Xb0s6",
    "outputId": "5edb90ed-6922-48e5-e8e6-e640eca4b757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467483\r\n"
     ]
    }
   ],
   "source": [
    "!find dataset -name '*.html' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Jq6rXifpNuMx",
    "outputId": "e1183140-3b20-4f26-97f8-e6624acdc182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.7)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from langdetect) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xais9mEzlDxi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tables-3.6.1:\r\n",
      "  Successfully uninstalled tables-3.6.1\r\n",
      "Collecting tables\r\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/cb/4097be890a773af95343389faa8c283b0d9ff606f144227a548461dcbdd5/tables-3.6.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from tables) (1.17.3)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables) (2.7.0)\r\n",
      "Installing collected packages: tables\r\n",
      "Successfully installed tables-3.6.1\r\n"
     ]
    }
   ],
   "source": [
    "# Reinstall pytables for hdf support (google colab has old & glitchy pytables)\n",
    "#!pip uninstall -y tables\n",
    "#!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "TFHmGj7_7F5y",
    "outputId": "8d31a9fe-f718-47a2-9a74-3c7ddfb8a720"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/467483 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "  0%|          | 24/467483 [00:00<6:00:22, 21.62it/s][Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "  0%|          | 1158/467483 [00:03<25:15, 307.61it/s][Parallel(n_jobs=-1)]: Done 998 tasks      | elapsed:    3.5s\n",
      "  1%|          | 3654/467483 [00:09<19:44, 391.45it/s][Parallel(n_jobs=-1)]: Done 3558 tasks      | elapsed:    9.9s\n",
      "  2%|▏         | 7302/467483 [00:18<19:28, 393.74it/s][Parallel(n_jobs=-1)]: Done 7142 tasks      | elapsed:   18.9s\n",
      "  3%|▎         | 11910/467483 [00:29<18:18, 414.79it/s][Parallel(n_jobs=-1)]: Done 11750 tasks      | elapsed:   29.9s\n",
      "  4%|▎         | 17478/467483 [00:43<17:46, 421.92it/s][Parallel(n_jobs=-1)]: Done 17382 tasks      | elapsed:   43.7s\n",
      "  5%|▌         | 24198/467483 [01:00<17:31, 421.50it/s][Parallel(n_jobs=-1)]: Done 24038 tasks      | elapsed:  1.0min\n",
      "  7%|▋         | 31878/467483 [01:19<18:38, 389.32it/s][Parallel(n_jobs=-1)]: Done 31718 tasks      | elapsed:  1.3min\n",
      "  9%|▊         | 40518/467483 [01:40<16:38, 427.69it/s][Parallel(n_jobs=-1)]: Done 40422 tasks      | elapsed:  1.7min\n",
      " 11%|█         | 50310/467483 [02:04<17:24, 399.53it/s][Parallel(n_jobs=-1)]: Done 50150 tasks      | elapsed:  2.1min\n",
      " 13%|█▎        | 61062/467483 [02:30<16:33, 409.15it/s][Parallel(n_jobs=-1)]: Done 60902 tasks      | elapsed:  2.5min\n",
      " 16%|█▌        | 72774/467483 [03:00<16:33, 397.20it/s][Parallel(n_jobs=-1)]: Done 72678 tasks      | elapsed:  3.0min\n",
      " 18%|█▊        | 85638/467483 [03:32<14:19, 444.32it/s][Parallel(n_jobs=-1)]: Done 85478 tasks      | elapsed:  3.5min\n",
      " 21%|██▏       | 99462/467483 [04:06<14:43, 416.32it/s][Parallel(n_jobs=-1)]: Done 99302 tasks      | elapsed:  4.1min\n",
      " 24%|██▍       | 114246/467483 [04:42<14:59, 392.92it/s][Parallel(n_jobs=-1)]: Done 114150 tasks      | elapsed:  4.7min\n",
      " 28%|██▊       | 130182/467483 [05:20<14:31, 386.83it/s][Parallel(n_jobs=-1)]: Done 130022 tasks      | elapsed:  5.3min\n",
      " 31%|███▏      | 147078/467483 [06:02<11:55, 447.81it/s][Parallel(n_jobs=-1)]: Done 146918 tasks      | elapsed:  6.0min\n",
      " 35%|███▌      | 164934/467483 [06:45<11:44, 429.43it/s][Parallel(n_jobs=-1)]: Done 164838 tasks      | elapsed:  6.8min\n",
      " 39%|███▉      | 183942/467483 [07:32<11:13, 420.85it/s][Parallel(n_jobs=-1)]: Done 183782 tasks      | elapsed:  7.5min\n",
      " 44%|████▎     | 203910/467483 [08:21<11:04, 396.54it/s][Parallel(n_jobs=-1)]: Done 203750 tasks      | elapsed:  8.4min\n",
      " 48%|████▊     | 224838/467483 [09:12<09:40, 418.09it/s][Parallel(n_jobs=-1)]: Done 224742 tasks      | elapsed:  9.2min\n",
      " 53%|█████▎    | 246918/467483 [10:07<09:45, 376.72it/s][Parallel(n_jobs=-1)]: Done 246758 tasks      | elapsed: 10.1min\n",
      " 58%|█████▊    | 269958/467483 [11:05<08:12, 400.77it/s][Parallel(n_jobs=-1)]: Done 269798 tasks      | elapsed: 11.1min\n",
      " 63%|██████▎   | 293958/467483 [12:03<07:15, 398.86it/s][Parallel(n_jobs=-1)]: Done 293862 tasks      | elapsed: 12.1min\n",
      " 68%|██████▊   | 319110/467483 [13:05<06:28, 382.26it/s][Parallel(n_jobs=-1)]: Done 318950 tasks      | elapsed: 13.1min\n",
      " 74%|███████▍  | 345222/467483 [14:10<04:53, 416.08it/s][Parallel(n_jobs=-1)]: Done 345062 tasks      | elapsed: 14.2min\n",
      " 80%|███████▉  | 372294/467483 [15:16<03:41, 429.71it/s][Parallel(n_jobs=-1)]: Done 372198 tasks      | elapsed: 15.3min\n",
      " 86%|████████▌ | 400518/467483 [16:27<02:55, 381.91it/s][Parallel(n_jobs=-1)]: Done 400358 tasks      | elapsed: 16.5min\n",
      " 92%|█████████▏| 429702/467483 [17:41<01:37, 387.22it/s][Parallel(n_jobs=-1)]: Done 429542 tasks      | elapsed: 17.7min\n",
      " 98%|█████████▊| 459846/467483 [18:54<00:18, 408.79it/s][Parallel(n_jobs=-1)]: Done 459750 tasks      | elapsed: 18.9min\n",
      "100%|██████████| 467483/467483 [19:12<00:00, 405.51it/s]\n",
      "[Parallel(n_jobs=-1)]: Done 467483 out of 467483 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 467483 entries, 0 to 467482\n",
      "Data columns (total 3 columns):\n",
      "filename    467483 non-null object\n",
      "text        467483 non-null object\n",
      "lang        467385 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import langdetect\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process(fn):\n",
    "  with open(fn, 'r') as f:\n",
    "    text = BeautifulSoup(f, 'html.parser').get_text()\n",
    "  lang = None\n",
    "  try:\n",
    "    lang = langdetect.detect(text)\n",
    "  except:\n",
    "    pass\n",
    "  return [fn, text, lang]\n",
    "\n",
    "df = pd.DataFrame(data = Parallel(n_jobs=-1, verbose=3)(delayed(process)(fn) for fn in tqdm(files)),\n",
    "                  columns=['filename', 'text', 'lang'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ru       120468\n",
       "en       107186\n",
       "es        38144\n",
       "ar        28138\n",
       "uk        16790\n",
       "fr        15367\n",
       "de        14627\n",
       "fa        14392\n",
       "pt        12168\n",
       "id        12062\n",
       "it        11338\n",
       "el         9666\n",
       "bg         8787\n",
       "ko         7705\n",
       "tr         5456\n",
       "vi         4360\n",
       "no         3326\n",
       "nl         3058\n",
       "ro         2870\n",
       "ml         2829\n",
       "ja         2656\n",
       "hi         2584\n",
       "cs         2493\n",
       "hu         2309\n",
       "th         2144\n",
       "sl         1902\n",
       "hr         1755\n",
       "te         1564\n",
       "ca         1503\n",
       "zh-tw      1458\n",
       "mr         1389\n",
       "sv         1189\n",
       "sk         1140\n",
       "he         1124\n",
       "ta          750\n",
       "pl          701\n",
       "bn          670\n",
       "zh-cn       504\n",
       "lt          345\n",
       "tl          109\n",
       "sw           82\n",
       "so           63\n",
       "mk           54\n",
       "et           52\n",
       "ur           50\n",
       "lv           35\n",
       "af           15\n",
       "da            7\n",
       "sq            1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227654, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['lang'] == 'en') | (df['lang'] == 'ru')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "UzK7j00FLCSP",
    "outputId": "8bdebf92-ac9f-4925-b552-281d769eabdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/20191108/15/1491978796208217930.html</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNewcastle United v Bou...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/20191108/15/6359253557838878602.html</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nМинкомсвязь негативно ...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset/20191108/15/8549607152500932485.html</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTether Responds to Mar...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset/20191108/15/3752801377276103486.html</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnger over Las Vegas b...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset/20191108/15/5545714965965021212.html</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmerican Truck Simulat...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename  \\\n",
       "0   dataset/20191108/15/1491978796208217930.html   \n",
       "4   dataset/20191108/15/6359253557838878602.html   \n",
       "6   dataset/20191108/15/8549607152500932485.html   \n",
       "7   dataset/20191108/15/3752801377276103486.html   \n",
       "10  dataset/20191108/15/5545714965965021212.html   \n",
       "\n",
       "                                                 text lang  \n",
       "0   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNewcastle United v Bou...   en  \n",
       "4   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nМинкомсвязь негативно ...   ru  \n",
       "6   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTether Responds to Mar...   en  \n",
       "7   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnger over Las Vegas b...   en  \n",
       "10  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmerican Truck Simulat...   en  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "64elhLuCLCS1",
    "outputId": "ddd82335-fd06-4e11-bfff-fe45ea6e8b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 755315112 Nov 22 20:50 fe1.h5\r\n",
      "CPU times: user 1.64 s, sys: 3.03 s, total: 4.66 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_hdf('fe1.h5', 'fe1')\n",
    "!ls -l fe1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "Pw3PTGVTLCS5",
    "outputId": "e16c935f-4c43-4893-9a43-d997578b18cf"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#import pandas as pd\n",
    "#df = pd.read_hdf('fe1.h5')\n",
    "#df.info()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "telegram_data_clustering_contest_FE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
