{"cells":[{"metadata":{"id":"N0yu5vfBwu-9","colab_type":"text"},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n</center> \n     \n## <center>  [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n\n#### <center> Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko) \n\n# <center>Assignment #2. Fall 2019\n## <center> Part 2. Gradient boosting"},{"metadata":{"id":"0pjMVR-Fwu_G","colab_type":"text"},"cell_type":"markdown","source":"**In this assignment, you're asked to beat a baseline in the [\"Flight delays\" competition](https://www.kaggle.com/c/flight-delays-fall-2018).**\n\nThis time we decided to share a pretty decent CatBoost baseline, you'll have to improve the provided solution.\n\nPrior to working on the assignment, you'd better check out the corresponding course material:\n 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) \n 2. Ensembles:\n  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n  - [Random Forest](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting) \n   - Logistic regression, Random Forest, and LightGBM in the \"Kaggle Forest Cover Type Prediction\" competition: [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n 4. You can also practice with demo assignments, which are simpler and already shared with solutions:\n  - \"Decision trees with a toy task and the UCI Adult dataset\": [assignment](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n  - \"Logistic Regression and Random Forest in the credit scoring problem\": [assignment](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n 5. There are also 7 video lectures on trees, forests, boosting and their applications: [mlcourse.ai/video](https://mlcourse.ai/video) \n 6. mlcourse.ai tutorials on [categorical feature encoding](https://www.kaggle.com/waydeherman/tutorial-categorical-encoding) (by Wayde Herman) and [CatBoost](https://www.kaggle.com/mitribunskiy/tutorial-catboost-overview) (by Mikhail Tribunskiy)\n 7. Last but not the least: [Public Kernels](https://www.kaggle.com/c/flight-delays-fall-2018/notebooks) in this competition\n\n### Your task is to:\n 1. beat **\"A2 baseline (10 credits)\"** on Public LB (**0.75914** LB score)\n 2. rename your [team](https://www.kaggle.com/c/flight-delays-fall-2018/team) in full accordance with A1 and the [course rating](https://docs.google.com/spreadsheets/d/15e1K0tg5ponA5R6YQkZfihrShTDLAKf5qeKaoVCiuhQ/) (to appear on 16.09.2019)\n \nThis task is intended to be relatively easy. Here you are not required to upload your reproducible solution.\n \n### <center> Deadline for A2: 2019 October 6, 20:59 CET (London time)"},{"metadata":{"trusted":true,"id":"LVjrN8oUwu_L","colab_type":"code","colab":{}},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom category_encoders.target_encoder import TargetEncoder\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"M_CneG2Owu_f","colab_type":"code","colab":{}},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom IPython.display import FileLink\nimport seaborn as sns\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"6hfXxNg6wu_w","colab_type":"code","outputId":"54fb94d0-a17a-4a77-ced1-d559e1ff1f68","colab":{"base_uri":"https://localhost:8080/","height":416}},"cell_type":"code","source":"!pwd\n!ls -l\n!ls -lR ../input/","execution_count":null,"outputs":[]},{"metadata":{"id":"8NZZYI3vGr6E","colab_type":"text"},"cell_type":"markdown","source":"**Read previously saved data**"},{"metadata":{"id":"-28aJP9pKD8n","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"#train_df = pd.read_hdf('../input/mlcourse-ai-fall-2019-xgboost/train.h5')\n#test_df = pd.read_hdf('../input/mlcourse-ai-fall-2019-xgboost/test.h5')","execution_count":0,"outputs":[]},{"metadata":{"id":"OGnqt4RwGWrZ","colab_type":"code","colab":{},"trusted":false},"cell_type":"code","source":"train_df = pd.read_hdf('../input/mlcourse-ai-fall-2019-xgboost/train_enc.h5')\n#test_df = pd.read_hdf('../input/mlcourse-ai-fall-2019-xgboost/test_enc.h5')\ny = pd.read_hdf('../input/mlcourse-ai-fall-2019-xgboost/y.h5')","execution_count":0,"outputs":[]},{"metadata":{"id":"AxUtJAPRwvDG","colab_type":"text"},"cell_type":"markdown","source":"**Train XGBoost**"},{"metadata":{"id":"CoUyP1AXOLOw","colab_type":"code","outputId":"84c50880-f857-49e3-b723-3100243cbe88","colab":{"base_uri":"https://localhost:8080/","height":260},"trusted":true},"cell_type":"code","source":"%%time\n# measure performance (GPU)\nXGBRegressor(tree_method='gpu_hist').fit(train_df[:10000], y[:10000])","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'XGBRegressor' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'XGBRegressor' is not defined"]}]},{"metadata":{"id":"30Y-zlTnC1kO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"a5bebf6b-ecc8-4b2e-97c4-219c5d39ab90","trusted":false},"cell_type":"code","source":"%%time\n# measure performance (CPU)\nXGBRegressor().fit(train_df[:10000], y[:10000])","execution_count":null,"outputs":[]},{"metadata":{"id":"3lYHYDT2R0bU","colab_type":"text"},"cell_type":"markdown","source":"Use different **random_state** here."},{"metadata":{"id":"NL6HDRWfMncy","colab_type":"code","outputId":"b9d17d9d-b904-4ff9-c12d-0a57cc25a954","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df, y, test_size=0.3, random_state=42, stratify=y)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"KOUsB2ztoCQ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"619c58e0-145b-422e-99a0-629c474b1689","trusted":false},"cell_type":"code","source":"%%time\nparams = {'max_depth': range(1, 101, 10), 'n_estimators': range(1, 1001, 100)}\ngrid = GridSearchCV(XGBRegressor(random_state=17, tree_method='gpu_hist'), params, cv=3, scoring='roc_auc', verbose=True)\ngrid.fit(X_train, y_train)\nprint(grid.best_score_)\nprint(roc_auc_score(y_valid, grid.best_estimator_.predict(X_valid)))\nplt.figure(figsize=(120,4))\nplt.plot([str(x) for x in grid.cv_results_['params']], grid.cv_results_['mean_test_score'])\nplt.xticks(rotation=90)\nplt.title('ROC AUC / train params')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Target is 0.756 ROC AUC**"},{"metadata":{"trusted":true,"id":"i2P0HcSswvDa","colab_type":"code","outputId":"d10dda9e-e4c1-4739-e12f-4e4014e8d9d3","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":"pickle.dump(grid, open(\"grid.pkl\", \"wb\"))\nFileLink('grid.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xhqWK0vywvEa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"0b859372-088b-4368-dd5e-108d90cc9858"},"cell_type":"code","source":"!ls -l","execution_count":null,"outputs":[]},{"metadata":{"id":"BuEW23kcwvEl","colab_type":"text"},"cell_type":"markdown","source":"Now's your turn! Go and improve the model to beat **\"A2 baseline (10 credits)\"** - **0.75914** LB score. It's crucial to come up with some good features. \n\nFor discussions, stick to the **#a2_kaggle_fall2019** thread in the **mlcourse_ai_news** [ODS Slack](http://opendatascience.slack.com) channel. Serhii Romanenko (@serhii_romanenko) will be there to help. \n\nWelcome to Kaggle!\n\n![img](https://habrastorage.org/webt/fs/42/ms/fs42ms0r7qsoj-da4x7yfntwrbq.jpeg)\n*from the [\"Nerd Laughing Loud\"](https://www.kaggle.com/general/76963) thread.*"}],"metadata":{"colab":{"name":"mlcourse-ai-fall-2019-xgboost","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}